{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Datasets\n",
    "\n",
    "**JFLEG Dataset**\n",
    "\n",
    "```bash\n",
    "git clone https://huggingface.co/datasets/jhu-clsp/jfleg\n",
    "```\n",
    "\n",
    "**Lang-8 Dataset**\n",
    "\n",
    "You can download the Lang-8 corpora from the download page.\n",
    "[Download the Lang-8 corpora](http://docs.google.com/forms/d/17gZZsC_rnaACMXmPiab3kjqBEtRHPMz0UG9Dk-x_F0k)\n",
    "\n",
    "**Cola Dataset**\n",
    "\n",
    "[Download the CoLA dataset](https://nyu-mll.github.io/CoLA/cola_public_1.1.zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hv/396xkstx5nzcqv2zhyyq6rbm0000gn/T/ipykernel_8158/3515241076.py:8: DtypeWarning: Columns (9,10,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, header=None, names=columns, sep=sep)\n",
      "100%|██████████| 1003020/1003020 [00:00<00:00, 1053080.37it/s]\n",
      "100%|██████████| 1003020/1003020 [00:00<00:00, 1017686.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grammar: But I found out that her parents got ...</td>\n",
       "      <td>correct: But I found out that her parents got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grammar: And you?</td>\n",
       "      <td>correct: And you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grammar:</td>\n",
       "      <td>correct:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grammar: A haveiolence by the Yokoduna is a fi...</td>\n",
       "      <td>correct: This haveiolence by the Yokozuna is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grammar: My university started last monday and...</td>\n",
       "      <td>correct: My university, as well as some clubs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003015</th>\n",
       "      <td>grammar: I will never fotgot that moment.</td>\n",
       "      <td>correct: I will never forget that moment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003016</th>\n",
       "      <td>grammar: Work so well in the learning of Japan...</td>\n",
       "      <td>correct: Work so well in the learning of Japan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003017</th>\n",
       "      <td>grammar: My favorite foreign drama program</td>\n",
       "      <td>correct: My favorite foreign drama program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003018</th>\n",
       "      <td>grammar: Hi!</td>\n",
       "      <td>correct: Hi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003019</th>\n",
       "      <td>grammar: I wish I had bought that skirt that t...</td>\n",
       "      <td>correct: I wish I had bought that skirt yester...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003020 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     input  \\\n",
       "0        grammar: But I found out that her parents got ...   \n",
       "1                                        grammar: And you?   \n",
       "2                                                grammar:    \n",
       "3        grammar: A haveiolence by the Yokoduna is a fi...   \n",
       "4        grammar: My university started last monday and...   \n",
       "...                                                    ...   \n",
       "1003015          grammar: I will never fotgot that moment.   \n",
       "1003016  grammar: Work so well in the learning of Japan...   \n",
       "1003017         grammar: My favorite foreign drama program   \n",
       "1003018                                       grammar: Hi!   \n",
       "1003019  grammar: I wish I had bought that skirt that t...   \n",
       "\n",
       "                                                    target  \n",
       "0        correct: But I found out that her parents got ...  \n",
       "1                                        correct: And you?  \n",
       "2                                                correct:   \n",
       "3        correct: This haveiolence by the Yokozuna is a...  \n",
       "4        correct: My university, as well as some clubs,...  \n",
       "...                                                    ...  \n",
       "1003015          correct: I will never forget that moment.  \n",
       "1003016  correct: Work so well in the learning of Japan...  \n",
       "1003017         correct: My favorite foreign drama program  \n",
       "1003018                                       correct: Hi!  \n",
       "1003019  correct: I wish I had bought that skirt yester...  \n",
       "\n",
       "[1003020 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def read_dataset(base_path, file_name, columns, usecols=None, explode_col=None, rename_cols=None, sep=','):\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    if file_name.endswith('.csv') or file_name.endswith('.tsv'):\n",
    "        df = pd.read_csv(file_path, header=None, names=columns, sep=sep)\n",
    "    elif file_name.endswith('.parquet'):\n",
    "        df = pd.read_parquet(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format for {file_name}\")\n",
    "    \n",
    "    if usecols:\n",
    "        df = df[usecols]\n",
    "    if explode_col:\n",
    "        df = df.explode(explode_col).reset_index(drop=True)\n",
    "    if rename_cols:\n",
    "        df = df.rename(columns=rename_cols)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_df(df, target_prefix='', input_prefix=''):\n",
    "    replacements = [\n",
    "        (\" \\.\", \".\"), \n",
    "        (\" ,\", \",\"),\n",
    "        (\" '\", \"'\"),\n",
    "        (\" \\?\", \"?\"),\n",
    "        (\" !\", \"!\"),\n",
    "        (\" :\", \":\"),\n",
    "        (\" ;\", \";\"),\n",
    "        (\" n't\", \" not\"),\n",
    "        (\" v\", \" have\"),\n",
    "        (\"2 0 0 6\", \"2006\"),\n",
    "        (\"5 5\", \"55\"),\n",
    "        (\"4 0 0\", \"400\"),\n",
    "        (\"1 7-5 0\", \"1750\"),\n",
    "        (\"2 0 %\", \"20%\"),\n",
    "        (\"5 0\", \"50\"),\n",
    "        (\"1 2\", \"12\"),\n",
    "        (\"1 0\", \"10\"),\n",
    "        (\" 'll\", \" will\"),\n",
    "        (\" 're\", \" are\"),\n",
    "        (\" 's\", \" is\"),\n",
    "        (\" 've\", \" have\"),\n",
    "        (\" 'd\", \" would\"),\n",
    "        (\" 'm\", \" am\"),\n",
    "        (\" 'em\", \" them\"),\n",
    "        (\" 'clock\", \"'clock\"),\n",
    "        (\" 't\", \" not\"),\n",
    "        (\" 'cause\", \"'cause\"),\n",
    "        (\" 'til\", \" until\"),\n",
    "        (\" 'bout\", \" about\"),\n",
    "        (\" 'round\", \" around\"),\n",
    "        (\"\\\"\", \"\"),\n",
    "    ]\n",
    "    df['input'] = df['input'].fillna('')\n",
    "    df['target'] = df['target'].fillna(df['input'])\n",
    "    \n",
    "    for rep in replacements:\n",
    "        df['input'] = df['input'].str.replace(rep[0], rep[1], regex=True)\n",
    "        df['target'] = df['target'].str.replace(rep[0], rep[1], regex=True)\n",
    "\n",
    "    df = df.map(lambda x: x.replace('\"', '') if isinstance(x, str) else x)\n",
    "    if target_prefix:\n",
    "        df['target'] = target_prefix + df['target']\n",
    "    if input_prefix:\n",
    "        df['input'] = input_prefix + df['input']\n",
    "    \n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "base_raw_path = '../data/raw'\n",
    "base_processed_path = '../data/processed'\n",
    "\n",
    "# COLA Dataset\n",
    "cola_columns = ['sentence_source', 'target', 'target_notes', 'sentence']\n",
    "cola_test_df = read_dataset(base_raw_path, 'cola_public/in_domain_dev.tsv', cola_columns, usecols=['sentence', 'target'], sep='\\t')\n",
    "cola_train_df = read_dataset(base_raw_path, 'cola_public/in_domain_train.tsv', cola_columns, usecols=['sentence', 'target'], sep='\\t')\n",
    "cola_df = pd.concat([cola_test_df, cola_train_df], ignore_index=True)\n",
    "cola_df.to_csv(os.path.join(base_processed_path, 'test/cola.csv'), index=False)\n",
    "\n",
    "# JFLEG Dataset\n",
    "jfleg_train_df = read_dataset(base_raw_path, 'jfleg/validation-00000-of-00001.parquet', None, explode_col='corrections', rename_cols={'corrections': 'target', 'sentence': 'input'})\n",
    "jfleg_test_df = read_dataset(base_raw_path, 'jfleg/test-00000-of-00001.parquet', None, explode_col='corrections', rename_cols={'corrections': 'target', 'sentence': 'input'})\n",
    "\n",
    "# Lang-8 Dataset\n",
    "lang8_columns = ['num_corrections', 'serial_number', 'url', 'sentence_number', 'sentence', 'corrections_0', 'corrections_1', 'corrections_2', 'corrections_3', 'corrections_4', 'corrections_5', 'corrections_6', 'corrections_7']\n",
    "lang8_train_df = read_dataset(base_raw_path, 'lang-8-en-1.0/train.csv', lang8_columns, usecols=['sentence', 'corrections_0'], rename_cols={'corrections_0': 'target', 'sentence': 'input'})\n",
    "lang8_test_df = read_dataset(base_raw_path, 'lang-8-en-1.0/test.csv', lang8_columns, usecols=['sentence', 'corrections_0'], rename_cols={'corrections_0': 'target', 'sentence': 'input'})\n",
    "\n",
    "# Concatenate and Preprocess\n",
    "data_train_df = pd.concat([jfleg_train_df, lang8_train_df], ignore_index=True)\n",
    "data_test_df = pd.concat([jfleg_test_df, lang8_test_df], ignore_index=True)\n",
    "\n",
    "train_df = preprocess_df(data_train_df, target_prefix='correct: ', input_prefix='grammar: ')\n",
    "test_df = preprocess_df(data_test_df, target_prefix='correct: ', input_prefix='grammar: ')\n",
    "\n",
    "def extract_first_sentence(text):\n",
    "    # Define a regular expression pattern to match the first sentence\n",
    "    pattern = r'^.*?[.!?]'\n",
    "\n",
    "    # Find the first match of the pattern in the text\n",
    "    match = re.search(pattern, text)\n",
    "\n",
    "    if match:\n",
    "        # Extract the matched sentence\n",
    "        first_sentence = match.group(0)\n",
    "        return first_sentence.strip()  # Remove leading/trailing whitespace\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply the function to extract the first sentence\n",
    "train_df['input'] = train_df['input'].progress_apply(extract_first_sentence)\n",
    "train_df['target'] = train_df['target'].progress_apply(extract_first_sentence)\n",
    "\n",
    "train_df.to_csv('../data/raw/train.csv', index=False)\n",
    "test_df.to_csv('../data/raw/test.csv', index=False)\n",
    "\n",
    "# At this point, `train_df` and `test_df` are ready for further use\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv('../data/processed/train/tokenized_train.csv')\n",
    "\n",
    "n = 40\n",
    "split_dfs = np.array_split(train_df, n)\n",
    "for i, df in enumerate(split_dfs):\n",
    "    df.to_csv(f'../data/processed/train_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grammar: But I found out that her parents got ...</td>\n",
       "      <td>correct: But I found out that her parents got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grammar: And you?</td>\n",
       "      <td>correct: And you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grammar:</td>\n",
       "      <td>correct:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grammar: A haveiolence by the Yokoduna is a fi...</td>\n",
       "      <td>correct: This haveiolence by the Yokozuna is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grammar: My university started last monday and...</td>\n",
       "      <td>correct: My university, as well as some clubs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003015</th>\n",
       "      <td>grammar: I will never fotgot that moment.</td>\n",
       "      <td>correct: I will never forget that moment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003016</th>\n",
       "      <td>grammar: Work so well in the learning of Japan...</td>\n",
       "      <td>correct: Work so well in the learning of Japan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003017</th>\n",
       "      <td>grammar: My favorite foreign drama program</td>\n",
       "      <td>correct: My favorite foreign drama program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003018</th>\n",
       "      <td>grammar: Hi!</td>\n",
       "      <td>correct: Hi!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003019</th>\n",
       "      <td>grammar: I wish I had bought that skirt that t...</td>\n",
       "      <td>correct: I wish I had bought that skirt yester...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1003020 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     input  \\\n",
       "0        grammar: But I found out that her parents got ...   \n",
       "1                                        grammar: And you?   \n",
       "2                                                 grammar:   \n",
       "3        grammar: A haveiolence by the Yokoduna is a fi...   \n",
       "4        grammar: My university started last monday and...   \n",
       "...                                                    ...   \n",
       "1003015          grammar: I will never fotgot that moment.   \n",
       "1003016  grammar: Work so well in the learning of Japan...   \n",
       "1003017         grammar: My favorite foreign drama program   \n",
       "1003018                                       grammar: Hi!   \n",
       "1003019  grammar: I wish I had bought that skirt that t...   \n",
       "\n",
       "                                                    target  \n",
       "0        correct: But I found out that her parents got ...  \n",
       "1                                        correct: And you?  \n",
       "2                                                 correct:  \n",
       "3        correct: This haveiolence by the Yokozuna is a...  \n",
       "4        correct: My university, as well as some clubs,...  \n",
       "...                                                    ...  \n",
       "1003015          correct: I will never forget that moment.  \n",
       "1003016  correct: Work so well in the learning of Japan...  \n",
       "1003017         correct: My favorite foreign drama program  \n",
       "1003018                                       correct: Hi!  \n",
       "1003019  correct: I wish I had bought that skirt yester...  \n",
       "\n",
       "[1003020 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
